{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94f8c34-44eb-4ffb-ac69-286a10991517",
   "metadata": {},
   "source": [
    "## Initialization Script\n",
    "This cell contains the initialization script for setting up the Flask application with SQLAlchemy and Flask-Migrate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d3f0c-af1e-4b40-b763-c42c8a582b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from flask_migrate import Migrate\n",
    "from config import Config\n",
    "import logging\n",
    "\n",
    "# Initialize extensions\n",
    "db = SQLAlchemy()\n",
    "migrate = Migrate()\n",
    "\n",
    "def create_app():\n",
    "    # Create and configure the Flask application\n",
    "    app = Flask(__name__)\n",
    "    app.config.from_object(Config)\n",
    "    \n",
    "    # Initialize extensions\n",
    "    db.init_app(app)\n",
    "    migrate.init_app(app, db)\n",
    "    \n",
    "    # Set up logging\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "    # Import and register blueprints\n",
    "    from . import routes, models\n",
    "    \n",
    "    # Example of how to register a blueprint\n",
    "    # from .routes import main as main_blueprint\n",
    "    # app.register_blueprint(main_blueprint)\n",
    "    \n",
    "    @app.errorhandler(500)\n",
    "    def internal_error(error):\n",
    "        db.session.rollback()\n",
    "        return \"500 error\"\n",
    "    \n",
    "    @app.errorhandler(404)\n",
    "    def not_found_error(error):\n",
    "        return \"404 error\"\n",
    "    \n",
    "    return app\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9a67ea-d371-42f7-a6d9-9c87958b91de",
   "metadata": {},
   "source": [
    "## Enhanced OpenAI Integration Script\n",
    "This cell contains the enhanced script for integrating with the OpenAI API, with added flexibility for model selection, adjustable token limits, and improved error handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dea821-d9b0-47c8-934e-4061b97cd55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set the OpenAI API key from environment variables\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def ask_openai(prompt, model=\"text-davinci-003\", max_tokens=150):\n",
    "    \"\"\"\n",
    "    Send a prompt to the OpenAI API and return the generated response.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The input prompt to send to the OpenAI model.\n",
    "        model (str, optional): The OpenAI model to use. Defaults to \"text-davinci-003\".\n",
    "        max_tokens (int, optional): The maximum number of tokens to generate. Defaults to 150.\n",
    "\n",
    "    Returns:\n",
    "        str: The text generated by the OpenAI model in response to the prompt.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            engine=model,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "    except openai.error.OpenAIError as e:\n",
    "        logging.error(f\"OpenAI API error: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    prompt = \"Write a short story about a cat who can talk.\"\n",
    "    response = ask_openai(prompt, model=\"text-davinci-003\", max_tokens=200)\n",
    "    if response:\n",
    "        print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f1b57c-1b58-4b35-86ba-cc083dcb9664",
   "metadata": {},
   "source": [
    "## Combined OCR Module\n",
    "This cell contains the combined OCR module that uses Google Vision for OCR and OpenAI for text enhancement. It includes improved logging, error handling, and flexible configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463026a4-d9af-4f8b-9d2c-99ec5e8fa05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from google_vision_ocr import perform_ocr, set_credentials\n",
    "from openai_post_processing import enhance_ocr_text\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def process_image(image_path, credentials_path=None):\n",
    "    \"\"\"\n",
    "    Process an image to extract and enhance text using Google Vision OCR and OpenAI.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The path to the image file.\n",
    "        credentials_path (str, optional): The path to the Google Cloud credentials JSON file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of enhanced texts extracted from the image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if credentials_path:\n",
    "            set_credentials(credentials_path)\n",
    "            logging.info(f\"Credentials set from: {credentials_path}\")\n",
    "        ocr_texts = perform_ocr(image_path)\n",
    "        logging.info(f\"OCR completed successfully for image: {image_path}\")\n",
    "        enhanced_texts = [enhance_ocr_text(text.description) for text in ocr_texts]\n",
    "        logging.info(\"Text enhancement completed successfully.\")\n",
    "        return enhanced_texts\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Image file not found: {image_path}\")\n",
    "        return []\n",
    "    except ValueError as e:\n",
    "        logging.error(f\"Error during OCR or text enhancement: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "# Ensure example usage only runs when the script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = input(\"Enter the path to your image: \")\n",
    "    credentials_path = input(\"Enter the path to your Google Cloud credentials JSON file (optional): \").strip()\n",
    "    try:\n",
    "        results = process_image(image_path, credentials_path if credentials_path else None)\n",
    "        if results:\n",
    "            print(\"\\nEnhanced Texts:\")\n",
    "            for result in results:\n",
    "                print(result)\n",
    "        else:\n",
    "            print(\"No texts were enhanced.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d40885-03be-4310-8062-0913da45a3a9",
   "metadata": {},
   "source": [
    "# VEDA OCR Processing Setup\n",
    "\n",
    "This Jupyter Notebook will guide you through setting up and running the OCR processing component of VEDA. We will use a Flask application to handle OCR requests and process images using the combined OCR module.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before we begin, ensure you have the following installed:\n",
    "- Python 3.7 or later\n",
    "- Flask\n",
    "- filetype\n",
    "- Your OCR module dependencies (e.g., Tesseract, Google Vision API, etc.)\n",
    "\n",
    "## Step 1: Setting Up the Virtual Environment\n",
    "\n",
    "First, let's create and activate a virtual environment.\n",
    "\n",
    "```bash\n",
    "# Create a virtual environment\n",
    "python -m venv venv\n",
    "\n",
    "# Activate the virtual environment\n",
    "# On Windows\n",
    "venv\\Scripts\\activate\n",
    "# On Unix or MacOS\n",
    "source venv/bin/activate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2fe72f-4d47-4f1e-8173-ff64a51e18f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from combined_ocr_module import process_image\n",
    "import logging\n",
    "import os\n",
    "import tempfile\n",
    "import filetype\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s [%(levelname)s] %(message)s', \n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/ocr', methods=['POST'])\n",
    "def ocr_endpoint():\n",
    "    \"\"\"\n",
    "    Endpoint to handle OCR processing requests.\n",
    "    Expects an image file and optional credentials path in the form data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Retrieve the uploaded image file from the request\n",
    "        image_file = request.files['image']\n",
    "        \n",
    "        # Validate the file type\n",
    "        if not filetype.guess(image_file.stream):\n",
    "            logging.warning('Invalid image file received.')\n",
    "            return jsonify({'error': 'Invalid image file'}), 400\n",
    "        \n",
    "        # Save the image file to a temporary location\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
    "            image_path = temp_file.name\n",
    "            image_file.save(image_path)\n",
    "            logging.info(f'Image saved to {image_path}')\n",
    "\n",
    "        # Retrieve credentials path from the form data\n",
    "        credentials_path = request.form.get('credentials_path')\n",
    "        if credentials_path:\n",
    "            logging.info(f'Using credentials from {credentials_path}')\n",
    "        else:\n",
    "            logging.warning('No credentials path provided.')\n",
    "\n",
    "        # Process the image using the combined OCR module\n",
    "        results = process_image(image_path, credentials_path)\n",
    "        return jsonify({'ocr_results': results})\n",
    "    \n",
    "    except KeyError as e:\n",
    "        error_message = f\"Missing form data: {e}\"\n",
    "        logging.error(error_message)\n",
    "        return jsonify({'error': error_message}), 400\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        error_message = f\"Credentials file not found: {e}\"\n",
    "        logging.error(error_message)\n",
    "        return jsonify({'error': error_message}), 400\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_message = f\"An error occurred: {e}\"\n",
    "        logging.error(error_message)\n",
    "        return jsonify({'error': error_message}), 500\n",
    "    \n",
    "    finally:\n",
    "        # Ensure the temporary image file is deleted after processing\n",
    "        if 'image_path' in locals() and os.path.exists(image_path):\n",
    "            os.remove(image_path)\n",
    "            logging.info(f'Temporary image file {image_path} deleted.')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Use environment variables for configuration\n",
    "    debug = os.getenv('FLASK_DEBUG', 'true').lower() in ['true', '1', 't']\n",
    "    port = int(os.getenv('FLASK_PORT', 5000))\n",
    "    app.run(debug=debug, port=port)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b40772-3b43-431e-a237-b19db8ef3e5b",
   "metadata": {},
   "source": [
    "# VEDA Project - OCR Module Development\n",
    "\n",
    "## Objective\n",
    "\n",
    "Develop a module to process images using OCR and enhance the extracted text using OpenAI's language model.\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. **Setup and Configuration**\n",
    "    - Configure logging for debugging and monitoring.\n",
    "    - Set up necessary environment variables for Google Cloud and OpenAI.\n",
    "\n",
    "2. **Function: `process_image`**\n",
    "    - Validate the image file type.\n",
    "    - Load the image.\n",
    "    - Perform OCR using Google Vision.\n",
    "    - Enhance the text using OpenAI.\n",
    "    - Return the results.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "### combined_ocr_module.py\n",
    "\n",
    "```python\n",
    "import logging\n",
    "from google.cloud import vision\n",
    "import openai\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "import filetype\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "class ImageProcessingError(Exception):\n",
    "    \"\"\"Custom exception for image processing errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "class OCRError(Exception):\n",
    "    \"\"\"Custom exception for OCR errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "class OpenAIError(Exception):\n",
    "    \"\"\"Custom exception for OpenAI errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "def process_image(image_path, credentials_path, openai_api_key):\n",
    "    \"\"\" \n",
    "    Process the given image to extract and enhance text using OCR and OpenAI.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_path: str, path to the image file\n",
    "    - credentials_path: str, path to the Google Cloud credentials file\n",
    "    - openai_api_key: str, OpenAI API key\n",
    "    \n",
    "    Returns:\n",
    "    - str, enhanced text from the image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the image file type is valid\n",
    "        if not filetype.is_image(image_path):\n",
    "            raise ImageProcessingError(\"Invalid image file type.\")\n",
    "\n",
    "        # Set up Google Cloud Vision client\n",
    "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_path\n",
    "        client = vision.ImageAnnotatorClient()\n",
    "\n",
    "        # Load image\n",
    "        with open(image_path, 'rb') as img_file:\n",
    "            content = img_file.read()\n",
    "\n",
    "        image = vision.Image(content=content)\n",
    "\n",
    "        # Perform OCR using Google Cloud Vision\n",
    "        response = client.text_detection(image=image)\n",
    "        texts = response.text_annotations\n",
    "        if not texts:\n",
    "            logging.warning(\"No text detected in the image.\")\n",
    "            raise OCRError(\"No text detected.\")\n",
    "\n",
    "        # Extract detected text\n",
    "        detected_text = texts[0].description\n",
    "        logging.info(f'Detected text: {detected_text}')\n",
    "\n",
    "        # Enhance text using OpenAI\n",
    "        openai.api_key = openai_api_key\n",
    "        enhanced_text = enhance_text_with_openai(detected_text)\n",
    "\n",
    "        return enhanced_text\n",
    "\n",
    "    except ImageProcessingError as e:\n",
    "        logging.error(f\"An error occurred during image processing: {e}\")\n",
    "        raise\n",
    "\n",
    "    except OCRError as e:\n",
    "        logging.error(f\"An error occurred during OCR: {e}\")\n",
    "        raise\n",
    "\n",
    "    except OpenAIError as e:\n",
    "        logging.error(f\"An error occurred during text enhancement: {e}\")\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unknown error occurred during image processing: {e}\")\n",
    "        raise ImageProcessingError(str(e))\n",
    "\n",
    "def enhance_text_with_openai(text, engine=\"text-davinci-003\"):\n",
    "    \"\"\" \n",
    "    Enhance the given text using OpenAI's language model.\n",
    "    \n",
    "    Parameters:\n",
    "    - text: str, the text to enhance\n",
    "    - engine: str, OpenAI engine to use (default: \"text-davinci-003\")\n",
    "    \n",
    "    Returns:\n",
    "    - str, enhanced text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            engine=engine,\n",
    "            prompt=f\"Enhance the following text:\\n\\n{text}\",\n",
    "            max_tokens=200,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        enhanced_text = response.choices[0].text.strip()\n",
    "        logging.info(f'Enhanced text: {enhanced_text}')\n",
    "\n",
    "        return enhanced_text\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred during text enhancement: {e}\")\n",
    "        raise OpenAIError(str(e))\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"path/to/your/image.jpg\"\n",
    "    credentials_path = \"path/to/your/credentials.json\"\n",
    "    openai_api_key = \"your_openai_api_key\"\n",
    "\n",
    "    try:\n",
    "        enhanced_text = process_image(image_path, credentials_path, openai_api_key)\n",
    "        print(f\"Enhanced Text: {enhanced_text}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3d13f-fd58-48d1-bbfc-1c484175269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from google.cloud import vision\n",
    "import openai\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "import filetype\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "class ImageProcessingError(Exception):\n",
    "    \"\"\"Custom exception for image processing errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "class OCRError(Exception):\n",
    "    \"\"\"Custom exception for OCR errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "class OpenAIError(Exception):\n",
    "    \"\"\"Custom exception for OpenAI errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "def process_image(image_path, credentials_path, openai_api_key):\n",
    "    \"\"\" \n",
    "    Process the given image to extract and enhance text using OCR and OpenAI.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_path: str, path to the image file\n",
    "    - credentials_path: str, path to the Google Cloud credentials file\n",
    "    - openai_api_key: str, OpenAI API key\n",
    "    \n",
    "    Returns:\n",
    "    - str, enhanced text from the image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the image file type is valid\n",
    "        if not filetype.is_image(image_path):\n",
    "            raise ImageProcessingError(\"Invalid image file type.\")\n",
    "\n",
    "        # Set up Google Cloud Vision client\n",
    "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_path\n",
    "        client = vision.ImageAnnotatorClient()\n",
    "\n",
    "        # Load image\n",
    "        with open(image_path, 'rb') as img_file:\n",
    "            content = img_file.read()\n",
    "\n",
    "        image = vision.Image(content=content)\n",
    "\n",
    "        # Perform OCR using Google Cloud Vision\n",
    "        response = client.text_detection(image=image)\n",
    "        texts = response.text_annotations\n",
    "        if not texts:\n",
    "            logging.warning(\"No text detected in the image.\")\n",
    "            raise OCRError(\"No text detected.\")\n",
    "\n",
    "        # Extract detected text\n",
    "        detected_text = texts[0].description\n",
    "        logging.info(f'Detected text: {detected_text}')\n",
    "\n",
    "        # Enhance text using OpenAI\n",
    "        openai.api_key = openai_api_key\n",
    "        enhanced_text = enhance_text_with_openai(detected_text)\n",
    "\n",
    "        return enhanced_text\n",
    "\n",
    "    except ImageProcessingError as e:\n",
    "        logging.error(f\"An error occurred during image processing: {e}\")\n",
    "        raise\n",
    "\n",
    "    except OCRError as e:\n",
    "        logging.error(f\"An error occurred during OCR: {e}\")\n",
    "        raise\n",
    "\n",
    "    except OpenAIError as e:\n",
    "        logging.error(f\"An error occurred during text enhancement: {e}\")\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unknown error occurred during image processing: {e}\")\n",
    "        raise ImageProcessingError(str(e))\n",
    "\n",
    "def enhance_text_with_openai(text, engine=\"text-davinci-003\"):\n",
    "    \"\"\" \n",
    "    Enhance the given text using OpenAI's language model.\n",
    "    \n",
    "    Parameters:\n",
    "    - text: str, the text to enhance\n",
    "    - engine: str, OpenAI engine to use (default: \"text-davinci-003\")\n",
    "    \n",
    "    Returns:\n",
    "    - str, enhanced text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            engine=engine,\n",
    "            prompt=f\"Enhance the following text:\\n\\n{text}\",\n",
    "            max_tokens=200,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        enhanced_text = response.choices[0].text.strip()\n",
    "        logging.info(f'Enhanced text: {enhanced_text}')\n",
    "\n",
    "        return enhanced_text\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred during text enhancement: {e}\")\n",
    "        raise OpenAIError(str(e))\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"path/to/your/image.jpg\"\n",
    "    credentials_path = \"path/to/your/credentials.json\"\n",
    "    openai_api_key = \"your_openai_api_key\"\n",
    "\n",
    "    try:\n",
    "        enhanced_text = process_image(image_path, credentials_path, openai_api_key)\n",
    "        print(f\"Enhanced Text: {enhanced_text}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ec383-9e99-438d-8a45-7786def774bb",
   "metadata": {},
   "source": [
    "# OpenAI Integration Script\n",
    "\n",
    "This script integrates OpenAI's language model to enhance text. It includes robust error handling, logging, and initialization functions to ensure smooth and reliable operations.\n",
    "\n",
    "## Script Overview\n",
    "\n",
    "1. **Logging Configuration**: Sets up logging to capture and display important events and errors.\n",
    "2. **Custom Exceptions**: Defines specific exceptions for handling different types of errors.\n",
    "3. **Function Definitions**:\n",
    "   - `initialize_openai_api(api_key)`: Initializes the OpenAI API with the provided key.\n",
    "   - `enhance_text_with_openai(text, engine=\"text-davinci-003\", max_tokens=200, temperature=0.7)`: Enhances the given text using OpenAI's language model.\n",
    "4. **Main Function**: Demonstrates the usage of the functions with an example text.\n",
    "\n",
    "## Script Code\n",
    "\n",
    "```python\n",
    "import openai\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "class OpenAIError(Exception):\n",
    "    \"\"\"Custom exception for OpenAI errors.\"\"\"\n",
    "\n",
    "def initialize_openai_api(api_key):\n",
    "    \"\"\"Initialize OpenAI API with the provided key.\"\"\"\n",
    "    if not api_key:\n",
    "        raise ValueError(\"OpenAI API key must be provided.\")\n",
    "    openai.api_key = api_key\n",
    "    logging.info(\"OpenAI API initialized with the provided key.\")\n",
    "\n",
    "def enhance_text_with_openai(text, engine=\"text-davinci-003\", max_tokens=200, temperature=0.7):\n",
    "    \"\"\"Enhance the given text using OpenAI's language model.\n",
    "\n",
    "    Args:\n",
    "    text (str): The text to enhance.\n",
    "    engine (str, optional): OpenAI engine to use. Defaults to \"text-davinci-003\".\n",
    "    max_tokens (int, optional): Maximum number of tokens for the response. Defaults to 200.\n",
    "    temperature (float, optional): Sampling temperature. Defaults to 0.7.\n",
    "\n",
    "    Returns:\n",
    "    str: Enhanced text.\n",
    "\n",
    "    Raises:\n",
    "    OpenAIError: If an error occurs during text enhancement.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input text and engine\n",
    "        if not isinstance(text, str):\n",
    "            raise ValueError(\"Input text must be a string.\")\n",
    "        if not isinstance(engine, str):\n",
    "            raise ValueError(\"Engine name must be a string.\")\n",
    "\n",
    "        response = openai.Completion.create(\n",
    "            engine=engine,\n",
    "            prompt=f\"Enhance the following text:\\n\\n{text}\",\n",
    "            max_tokens=max_tokens,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=temperature\n",
    "        )\n",
    "\n",
    "        enhanced_text = response.choices[0].text.strip()\n",
    "        logging.info(f'Enhanced text: {enhanced_text}')\n",
    "        return enhanced_text\n",
    "\n",
    "    except openai.error.APIError as e:\n",
    "        error_message = f\"OpenAI API error during text enhancement: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise OpenAIError(error_message)\n",
    "\n",
    "    except openai.error.InvalidRequestError as e:\n",
    "        error_message = f\"Invalid request to OpenAI API: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise OpenAIError(error_message)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"An error occurred during text enhancement: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise OpenAIError(error_message)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for example usage.\"\"\"\n",
    "    openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "    if not openai_api_key:\n",
    "        logging.error(\"OpenAI API key not found in environment variables.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        initialize_openai_api(openai_api_key)\n",
    "        text_to_enhance = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "        print(\"Processing text...\")\n",
    "        enhanced_text = enhance_text_with_openai(text_to_enhance)\n",
    "        print(f\"Enhanced Text:\\n{enhanced_text}\")\n",
    "\n",
    "    except (ValueError, OpenAIError) as e:\n",
    "        logging.error(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203cb0f8-f713-4c88-bd17-cde5f053a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "class OpenAIError(Exception):\n",
    "    \"\"\"Custom exception for OpenAI errors.\"\"\"\n",
    "\n",
    "def initialize_openai_api(api_key):\n",
    "    \"\"\"Initialize OpenAI API with the provided key.\"\"\"\n",
    "    if not api_key:\n",
    "        raise ValueError(\"OpenAI API key must be provided.\")\n",
    "    openai.api_key = api_key\n",
    "    logging.info(\"OpenAI API initialized with the provided key.\")\n",
    "\n",
    "def enhance_text_with_openai(text, engine=\"text-davinci-003\", max_tokens=200, temperature=0.7):\n",
    "    \"\"\"Enhance the given text using OpenAI's language model.\n",
    "\n",
    "    Args:\n",
    "    text (str): The text to enhance.\n",
    "    engine (str, optional): OpenAI engine to use. Defaults to \"text-davinci-003\".\n",
    "    max_tokens (int, optional): Maximum number of tokens for the response. Defaults to 200.\n",
    "    temperature (float, optional): Sampling temperature. Defaults to 0.7.\n",
    "\n",
    "    Returns:\n",
    "    str: Enhanced text.\n",
    "\n",
    "    Raises:\n",
    "    OpenAIError: If an error occurs during text enhancement.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input text and engine\n",
    "        if not isinstance(text, str):\n",
    "            raise ValueError(\"Input text must be a string.\")\n",
    "        if not isinstance(engine, str):\n",
    "            raise ValueError(\"Engine name must be a string.\")\n",
    "\n",
    "        response = openai.Completion.create(\n",
    "            engine=engine,\n",
    "            prompt=f\"Enhance the following text:\\n\\n{text}\",\n",
    "            max_tokens=max_tokens,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=temperature\n",
    "        )\n",
    "\n",
    "        enhanced_text = response.choices[0].text.strip()\n",
    "        logging.info(f'Enhanced text: {enhanced_text}')\n",
    "        return enhanced_text\n",
    "\n",
    "    except openai.error.APIError as e:\n",
    "        error_message = f\"OpenAI API error during text enhancement: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise OpenAIError(error_message)\n",
    "\n",
    "    except openai.error.InvalidRequestError as e:\n",
    "        error_message = f\"Invalid request to OpenAI API: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise OpenAIError(error_message)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"An error occurred during text enhancement: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise OpenAIError(error_message)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for example usage.\"\"\"\n",
    "    openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "    if not openai_api_key:\n",
    "        logging.error(\"OpenAI API key not found in environment variables.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        initialize_openai_api(openai_api_key)\n",
    "        text_to_enhance = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "        print(\"Processing text...\")\n",
    "        enhanced_text = enhance_text_with_openai(text_to_enhance)\n",
    "        print(f\"Enhanced Text:\\n{enhanced_text}\")\n",
    "\n",
    "    except (ValueError, OpenAIError) as e:\n",
    "        logging.error(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3187a6-4148-444f-82e6-d9a218c0f62a",
   "metadata": {},
   "source": [
    "# Google Vertex AI Integration Script\n",
    "\n",
    "This script integrates with Google Vertex AI to initialize the AI platform and make predictions using deployed models. It includes robust error handling, logging, and initialization functions.\n",
    "\n",
    "## Script Overview\n",
    "\n",
    "1. **Logging Configuration**: Sets up logging to capture and display important events and errors.\n",
    "2. **Custom Exceptions**: Defines specific exceptions for handling different types of errors.\n",
    "3. **Function Definitions**:\n",
    "   - `initialize_vertex_ai(credentials_path, project_id, location=\"us-central1\")`: Initializes Google Vertex AI with the provided credentials and project details.\n",
    "   - `predict_with_vertex_ai(model_name, instances)`: Makes predictions using a deployed model in Google Vertex AI.\n",
    "4. **Main Function**: Demonstrates the usage of the functions with example inputs.\n",
    "\n",
    "## Script Code\n",
    "\n",
    "```python\n",
    "import logging\n",
    "from google.cloud import aiplatform\n",
    "import os\n",
    "import yaml\n",
    "from google.api_core.exceptions import NotFound, InvalidArgument\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "class VertexAIError(Exception):\n",
    "    \"\"\"Custom exception for Google Vertex AI errors.\"\"\"\n",
    "\n",
    "def initialize_vertex_ai(credentials_path, project_id, location=\"us-central1\"):\n",
    "    \"\"\"Initialize Google Vertex AI with the provided credentials and project details.\n",
    "\n",
    "    Args:\n",
    "        credentials_path (str): Path to the Google Cloud credentials file.\n",
    "        project_id (str): Google Cloud project ID.\n",
    "        location (str, optional): Vertex AI region. Defaults to \"us-central1\".\n",
    "\n",
    "    Raises:\n",
    "        VertexAIError: If an error occurs during initialization.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_path\n",
    "        aiplatform.init(project=project_id, location=location)\n",
    "        logging.info(\"Google Vertex AI initialized.\")\n",
    "    except FileNotFoundError as e:\n",
    "        error_message = f\"Credentials file not found: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise VertexAIError(error_message)\n",
    "    except Exception as e:\n",
    "        error_message = f\"Failed to initialize Google Vertex AI: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise VertexAIError(error_message)\n",
    "\n",
    "def predict_with_vertex_ai(model_name, instances):\n",
    "    \"\"\"Make predictions using a deployed model in Google Vertex AI.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the deployed model.\n",
    "        instances (list): List of instances for prediction.\n",
    "\n",
    "    Returns:\n",
    "        list: Predictions from the model.\n",
    "\n",
    "    Raises:\n",
    "        VertexAIError: If an error occurs during prediction.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        endpoint = aiplatform.Endpoint(model_name)\n",
    "        predictions = endpoint.predict(instances=instances).predictions\n",
    "        logging.info(f\"Predictions: {predictions}\")\n",
    "        return predictions\n",
    "    except NotFound as e:\n",
    "        error_message = f\"Model or endpoint not found: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise VertexAIError(error_message)\n",
    "    except InvalidArgument as e:\n",
    "        error_message = f\"Invalid input data: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise VertexAIError(error_message)\n",
    "    except Exception as e:\n",
    "        error_message = f\"Failed to make predictions with Vertex AI: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise VertexAIError(error_message)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for example usage.\"\"\"\n",
    "    config_path = \"config.yaml\"\n",
    "    try:\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Configuration file not found at {config_path}\")\n",
    "        return\n",
    "\n",
    "    credentials_path = config.get('credentials_path')\n",
    "    project_id = config.get('project_id')\n",
    "    model_name = config.get('model_name')\n",
    "    location = config.get('location', \"us-central1\")\n",
    "\n",
    "    if not all([credentials_path, project_id, model_name]):\n",
    "        logging.error(\"Missing required configuration values.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        initialize_vertex_ai(credentials_path, project_id, location)\n",
    "\n",
    "        # Example input data\n",
    "        instances = [{\"input\": \"example input data\"}]\n",
    "\n",
    "        logging.info(\"Making predictions...\")\n",
    "        predictions = predict_with_vertex_ai(model_name, instances)\n",
    "        logging.info(f\"Predictions: {predictions}\")\n",
    "\n",
    "    except (ValueError, VertexAIError) as e:\n",
    "        logging.error(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b727da4a-f664-4d06-83e6-2049e1fb433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from google.cloud import aiplatform\n",
    "import os\n",
    "import yaml\n",
    "from google.api_core.exceptions import NotFound, InvalidArgument\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "class VertexAIError(Exception):\n",
    "    \"\"\"Custom exception for Google Vertex AI errors.\"\"\"\n",
    "\n",
    "def initialize_vertex_ai(credentials_path, project_id, location=\"us-central1\"):\n",
    "    \"\"\"Initialize Google Vertex AI with the provided credentials and project details.\n",
    "\n",
    "    Args:\n",
    "        credentials_path (str): Path to the Google Cloud credentials file.\n",
    "        project_id (str): Google Cloud project ID.\n",
    "        location (str, optional): Vertex AI region. Defaults to \"us-central1\".\n",
    "\n",
    "    Raises:\n",
    "        VertexAIError: If an error occurs during initialization.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_path\n",
    "        aiplatform.init(project=project_id, location=location)\n",
    "        logging.info(\"Google Vertex AI initialized.\")\n",
    "    except FileNotFoundError as e:\n",
    "        error_message = f\"Credentials file not found: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise VertexAIError(error_message)\n",
    "    except Exception as e:\n",
    "        error_message = f\"Failed to initialize Google Vertex AI: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise VertexAIError(error_message)\n",
    "\n",
    "def upload_model_to_vertex_ai(model_path, display_name, project_id, location=\"us-central1\"):\n",
    "    \"\"\"Upload a model to Google Vertex AI.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): Path to the model file.\n",
    "        display_name (str): Display name for the model in Vertex AI.\n",
    "        project_id (str): Google Cloud project ID.\n",
    "        location (str, optional): Vertex AI region. Defaults to \"us-central1\".\n",
    "\n",
    "    Returns:\n",
    "        model: The uploaded model.\n",
    "\n",
    "    Raises:\n",
    "        VertexAIError: If an error occurs during model upload.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = aiplatform.Model.upload(\n",
    "            display_name=display_name,\n",
    "            artifact_uri=model_path,\n",
    "            project=project_id,\n",
    "            location=location,\n",
    "        )\n",
    "        logging.info(f\"Model uploaded successfully: {model.resource_name}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        error_message = f\"Failed to upload model to Vertex AI: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise VertexAIError(error_message)\n",
    "\n",
    "def deploy_model_to_endpoint(model, endpoint_name, project_id, location=\"us-central1\"):\n",
    "    \"\"\"Deploy a model to an endpoint in Google Vertex AI.\n",
    "\n",
    "    Args:\n",
    "        model (Model): The model to deploy.\n",
    "        endpoint_name (str): Name of the endpoint to deploy the model to.\n",
    "        project_id (str): Google Cloud project ID.\n",
    "        location (str, optional): Vertex AI region. Defaults to \"us-central1\".\n",
    "\n",
    "    Returns:\n",
    "        endpoint: The deployed endpoint.\n",
    "\n",
    "    Raises:\n",
    "        VertexAIError: If an error occurs during model deployment.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        endpoint = aiplatform.Endpoint.create(\n",
    "            display_name=endpoint_name,\n",
    "            project=project_id,\n",
    "            location=location,\n",
    "        )\n",
    "        model.deploy(endpoint=endpoint)\n",
    "        logging.info(f\"Model deployed to endpoint: {endpoint.resource_name}\")\n",
    "        return endpoint\n",
    "    except Exception as e:\n",
    "        error_message = f\"Failed to deploy model to endpoint: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise VertexAIError(error_message)\n",
    "\n",
    "def predict_with_vertex_ai(endpoint, instances):\n",
    "    \"\"\"Make predictions using a deployed model in Google Vertex AI.\n",
    "\n",
    "    Args:\n",
    "        endpoint (Endpoint): The endpoint to use for prediction.\n",
    "        instances (list): List of instances for prediction.\n",
    "\n",
    "    Returns:\n",
    "        list: Predictions from the model.\n",
    "\n",
    "    Raises:\n",
    "        VertexAIError: If an error occurs during prediction.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        predictions = endpoint.predict(instances=instances).predictions\n",
    "        logging.info(f\"Predictions: {predictions}\")\n",
    "        return predictions\n",
    "    except NotFound as e:\n",
    "        error_message = f\"Model or endpoint not found: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise VertexAIError(error_message)\n",
    "    except InvalidArgument as e:\n",
    "        error_message = f\"Invalid input data: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise VertexAIError(error_message)\n",
    "    except Exception as e:\n",
    "        error_message = f\"Failed to make predictions with Vertex AI: {e}\"\n",
    "        logging.error(error_message)\n",
    "        raise VertexAIError(error_message)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for example usage.\"\"\"\n",
    "    config_path = \"config.yaml\"\n",
    "    try:\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Configuration file not found at {config_path}\")\n",
    "        return\n",
    "\n",
    "    credentials_path = config.get('credentials_path')\n",
    "    project_id = config.get('project_id')\n",
    "    model_path = config.get('model_path')\n",
    "    display_name = config.get('display_name')\n",
    "    endpoint_name = config.get('endpoint_name')\n",
    "    location = config.get('location', \"us-central1\")\n",
    "\n",
    "    if not all([credentials_path, project_id, model_path, display_name, endpoint_name]):\n",
    "        logging.error(\"Missing required configuration values.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        initialize_vertex_ai(credentials_path, project_id, location)\n",
    "        model = upload_model_to_vertex_ai(model_path, display_name, project_id, location)\n",
    "        endpoint = deploy_model_to_endpoint(model, endpoint_name, project_id, location)\n",
    "\n",
    "        # Example input data\n",
    "        instances = [{\"input\": \"example input data\"}]\n",
    "\n",
    "        logging.info(\"Making predictions...\")\n",
    "        predictions = predict_with_vertex_ai(endpoint, instances)\n",
    "        logging.info(f\"Predictions: {predictions}\")\n",
    "\n",
    "    except (ValueError, VertexAIError) as e:\n",
    "        logging.error(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96dba4-82f0-424d-b211-4d2275ebde28",
   "metadata": {},
   "source": [
    "# Models Script for VEDA\n",
    "\n",
    "In this notebook, we will review and enhance the `models.py` script for the VEDA project. The `models.py` script defines the database models using SQLAlchemy for the VEDA application. These models represent the database tables and their relationships.\n",
    "\n",
    "## User Model\n",
    "\n",
    "The `User` model represents the users of the VEDA application. It includes fields for storing user information such as username, email, password hash, and timestamps for creation and updates.\n",
    "\n",
    "```python\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from datetime import datetime\n",
    "from werkzeug.security import generate_password_hash, check_password_hash\n",
    "\n",
    "# Initialize the SQLAlchemy instance\n",
    "db = SQLAlchemy()\n",
    "\n",
    "class User(db.Model):\n",
    "    __tablename__ = 'users'\n",
    "    \n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    username = db.Column(db.String(150), nullable=False, unique=True)\n",
    "    email = db.Column(db.String(150), unique=True, nullable=False)\n",
    "    password_hash = db.Column(db.String(150), nullable=False)\n",
    "    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n",
    "    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n",
    "    \n",
    "    def set_password(self, password):\n",
    "        \"\"\"Hash and set the user's password.\"\"\"\n",
    "        self.password_hash = generate_password_hash(password)\n",
    "    \n",
    "    def check_password(self, password):\n",
    "        \"\"\"Check the user's password.\"\"\"\n",
    "        return check_password_hash(self.password_hash, password)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'<User {self.username}>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3085054d-9290-44e0-adc4-352735230539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from datetime import datetime\n",
    "from werkzeug.security import generate_password_hash, check_password_hash\n",
    "\n",
    "# Initialize the SQLAlchemy instance\n",
    "db = SQLAlchemy()\n",
    "\n",
    "class User(db.Model):\n",
    "    __tablename__ = 'users'\n",
    "    \n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    username = db.Column(db.String(150), nullable=False, unique=True)\n",
    "    email = db.Column(db.String(150), unique=True, nullable=False)\n",
    "    password_hash = db.Column(db.String(150), nullable=False)\n",
    "    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n",
    "    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n",
    "    \n",
    "    def set_password(self, password):\n",
    "        \"\"\"Hash and set the user's password.\"\"\"\n",
    "        self.password_hash = generate_password_hash(password)\n",
    "    \n",
    "    def check_password(self, password):\n",
    "        \"\"\"Check the user's password.\"\"\"\n",
    "        return check_password_hash(self.password_hash, password)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'<User {self.username}>'\n",
    "\n",
    "class Document(db.Model):\n",
    "    __tablename__ = 'documents'\n",
    "    \n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    title = db.Column(db.String(150), nullable=False)\n",
    "    content = db.Column(db.Text, nullable=False)\n",
    "    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n",
    "    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n",
    "    file_type = db.Column(db.String(50), nullable=True)  # Store file type, if applicable\n",
    "    file_size = db.Column(db.Integer, nullable=True)  # Store file size, if applicable\n",
    "    unique_id = db.Column(db.String(100), nullable=True)  # Store a unique identifier for the document\n",
    "    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)\n",
    "    user = db.relationship('User', backref=db.backref('documents', lazy=True))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'<Document {self.title}>'\n",
    "\n",
    "class OcrResult(db.Model):\n",
    "    __tablename__ = 'ocr_results'\n",
    "    \n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    document_id = db.Column(db.Integer, db.ForeignKey('documents.id'), nullable=False)\n",
    "    text = db.Column(db.Text, nullable=False)\n",
    "    confidence_scores = db.Column(db.JSON, nullable=True)  # Store confidence scores for the OCR results\n",
    "    bounding_boxes = db.Column(db.JSON, nullable=True)  # Store bounding boxes for the detected text\n",
    "    language = db.Column(db.String(50), nullable=True)  # Store the language of the detected text\n",
    "    created_at = db.Column(db.DateTime, default=datetime.utcnow)\n",
    "    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)\n",
    "    document = db.relationship('Document', backref=db.backref('ocr_results', lazy=True))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'<OcrResult {self.id}>'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3a3958-b39d-44a0-942b-35a2887ff8d3",
   "metadata": {},
   "source": [
    "## Flask Routes Integration\n",
    "\n",
    "This notebook section covers the integration of Flask routes for VEDA, including the interaction with OpenAI and Vertex AI.\n",
    "\n",
    "### Routes\n",
    "\n",
    "1. **Default Route (`/`)**\n",
    "    - Returns a simple message: \"Hello, VEDA!\"\n",
    "\n",
    "2. **Ask OpenAI Endpoint (`/ask_openai`)**\n",
    "    - Method: `POST`\n",
    "    - Description: Interacts with OpenAI to get a response based on the provided prompt.\n",
    "    - Request Body:\n",
    "        ```json\n",
    "        {\n",
    "            \"prompt\": \"Your question or prompt here\"\n",
    "        }\n",
    "        ```\n",
    "    - Response:\n",
    "        ```json\n",
    "        {\n",
    "            \"response\": \"OpenAI response here\"\n",
    "        }\n",
    "        ```\n",
    "\n",
    "3. **Predict Vertex AI Endpoint (`/predict_vertex_ai`)**\n",
    "    - Method: `POST`\n",
    "    - Description: Makes predictions using a deployed model on Vertex AI.\n",
    "    - Request Body:\n",
    "        ```json\n",
    "        {\n",
    "            \"endpoint_id\": \"Your Vertex AI endpoint ID\",\n",
    "            \"instances\": [\"Input data for prediction\"]\n",
    "        }\n",
    "        ```\n",
    "    - Response:\n",
    "        ```json\n",
    "        {\n",
    "            \"prediction\": \"Prediction results here\"\n",
    "        }\n",
    "        ```\n",
    "\n",
    "### Code\n",
    "\n",
    "Below is the Flask routes integration code with enhancements for better logging, error handling, and documentation.\n",
    "\n",
    "```python\n",
    "# Flask routes integration code\n",
    "# Ensure to review, comment, and apply as per the guidelines\n",
    "from flask import render_template, request, jsonify\n",
    "from veda_app import create_app\n",
    "from veda_app.openai_integration import ask_openai\n",
    "from veda_app.google_vertex_integration import init_vertex_ai, predict_with_vertex_ai\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Initialize the Flask app and Vertex AI\n",
    "app = create_app()\n",
    "init_vertex_ai()\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    \"\"\"Default route for VEDA.\"\"\"\n",
    "    return \"Hello, VEDA!\"\n",
    "\n",
    "def handle_api_error(error_message, status_code=500):\n",
    "    \"\"\"Helper function to handle API errors.\"\"\"\n",
    "    logging.error(error_message)\n",
    "    return jsonify({'error': error_message}), status_code\n",
    "\n",
    "@app.route('/ask_openai', methods=['POST'])\n",
    "def ask_openai_endpoint():\n",
    "    \"\"\"Endpoint to interact with OpenAI.\"\"\"\n",
    "    try:\n",
    "        data = request.json\n",
    "        prompt = data.get('prompt')\n",
    "        if not prompt or not isinstance(prompt, str):\n",
    "            return handle_api_error(\"Invalid prompt provided.\", 400)\n",
    "        \n",
    "        logging.info(f\"Received prompt: {prompt}\")\n",
    "        response = ask_openai(prompt)\n",
    "        logging.info(f\"OpenAI response: {response}\")\n",
    "        \n",
    "        return jsonify({'response': response})\n",
    "    \n",
    "    except Exception as e:\n",
    "        return handle_api_error(f\"An error occurred while interacting with OpenAI: {e}\")\n",
    "\n",
    "@app.route('/predict_vertex_ai', methods=['POST'])\n",
    "def predict_vertex_ai_endpoint():\n",
    "    \"\"\"Endpoint to make predictions using Vertex AI.\"\"\"\n",
    "    try:\n",
    "        data = request.json\n",
    "        endpoint_id = data.get('endpoint_id')\n",
    "        instances = data.get('instances')\n",
    "        \n",
    "        if not endpoint_id or not isinstance(endpoint_id, str):\n",
    "            return handle_api_error(\"Invalid endpoint ID provided.\", 400)\n",
    "        \n",
    "        if not instances or not isinstance(instances, list):\n",
    "            return handle_api_error(\"Invalid instances provided.\", 400)\n",
    "        \n",
    "        logging.info(f\"Endpoint ID: {endpoint_id}, Instances: {instances}\")\n",
    "        prediction = predict_with_vertex_ai(endpoint_id, instances)\n",
    "        logging.info(f\"Vertex AI prediction: {prediction}\")\n",
    "        \n",
    "        return jsonify({'prediction': prediction})\n",
    "    \n",
    "    except Exception as e:\n",
    "        return handle_api_error(f\"An error occurred while making predictions with Vertex AI: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Use environment variables for configuration\n",
    "    debug = os.getenv('FLASK_DEBUG', 'true').lower() in ['true', '1', 't']\n",
    "    port = int(os.getenv('FLASK_PORT', 5000))\n",
    "    app.run(debug=debug, port=port)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd7751f-4eee-4102-a759-a0f23959426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import render_template, request, jsonify\n",
    "from veda_app import create_app\n",
    "from veda_app.openai_integration import ask_openai\n",
    "from veda_app.google_vertex_integration import init_vertex_ai, predict_with_vertex_ai\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Initialize the Flask app and Vertex AI\n",
    "app = create_app()\n",
    "init_vertex_ai()\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    \"\"\"Default route for VEDA.\"\"\"\n",
    "    return \"Hello, VEDA!\"\n",
    "\n",
    "def handle_api_error(error_message, status_code=500):\n",
    "    \"\"\"Helper function to handle API errors.\"\"\"\n",
    "    logging.error(error_message)\n",
    "    return jsonify({'error': error_message}), status_code\n",
    "\n",
    "@app.route('/ask_openai', methods=['POST'])\n",
    "def ask_openai_endpoint():\n",
    "    \"\"\"Endpoint to interact with OpenAI.\"\"\"\n",
    "    try:\n",
    "        data = request.json\n",
    "        prompt = data.get('prompt')\n",
    "        if not prompt or not isinstance(prompt, str):\n",
    "            return handle_api_error(\"Invalid prompt provided.\", 400)\n",
    "        \n",
    "        logging.info(f\"Received prompt: {prompt}\")\n",
    "        response = ask_openai(prompt)\n",
    "        logging.info(f\"OpenAI response: {response}\")\n",
    "        \n",
    "        return jsonify({'response': response})\n",
    "    \n",
    "    except Exception as e:\n",
    "        return handle_api_error(f\"An error occurred while interacting with OpenAI: {e}\")\n",
    "\n",
    "@app.route('/predict_vertex_ai', methods=['POST'])\n",
    "def predict_vertex_ai_endpoint():\n",
    "    \"\"\"Endpoint to make predictions using Vertex AI.\"\"\"\n",
    "    try:\n",
    "        data = request.json\n",
    "        endpoint_id = data.get('endpoint_id')\n",
    "        instances = data.get('instances')\n",
    "        \n",
    "        if not endpoint_id or not isinstance(endpoint_id, str):\n",
    "            return handle_api_error(\"Invalid endpoint ID provided.\", 400)\n",
    "        \n",
    "        if not instances or not isinstance(instances, list):\n",
    "            return handle_api_error(\"Invalid instances provided.\", 400)\n",
    "        \n",
    "        logging.info(f\"Endpoint ID: {endpoint_id}, Instances: {instances}\")\n",
    "        prediction = predict_with_vertex_ai(endpoint_id, instances)\n",
    "        logging.info(f\"Vertex AI prediction: {prediction}\")\n",
    "        \n",
    "        return jsonify({'prediction': prediction})\n",
    "    \n",
    "    except Exception as e:\n",
    "        return handle_api_error(f\"An error occurred while making predictions with Vertex AI: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Use environment variables for configuration\n",
    "    debug = os.getenv('FLASK_DEBUG', 'true').lower() in ['true', '1', 't']\n",
    "    port = int(os.getenv('FLASK_PORT', 5000))\n",
    "    app.run(debug=debug, port=port)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
